if (packageVersion('httr') > "0.2" & packageVersion('httr') <= "0.6.1"){
fb_oauth <- oauth2.0_token(facebook, myapp,
scope=scope, cache=FALSE)
if (GET("https://graph.facebook.com/me", config(token=fb_oauth))$status==200){
message("Authentication successful.")
}
}
## httr version from 0.6 to 1.1
if (packageVersion('httr') > "0.6.1" & packageVersion('httr') < "1.2"){
Sys.setenv("HTTR_SERVER_PORT" = "1410/")
fb_oauth <- oauth2.0_token(facebook, myapp,
scope=scope, cache=FALSE)
if (GET("https://graph.facebook.com/me", config(token=fb_oauth))$status==200){
message("Authentication successful.")
}
}
## httr version after 1.2
if (packageVersion('httr') >= "1.2"){
fb_oauth <- oauth2.0_token(facebook, myapp,
scope=scope, cache=FALSE)
if (GET("https://graph.facebook.com/me", config(token=fb_oauth))$status==200){
message("Authentication successful.")
}
}
## identifying API version of token
error <- tryCatch(callAPI('https://graph.facebook.com/pablobarbera', fb_oauth),
error = function(e) e)
if (inherits(error, 'error')){
class(fb_oauth)[4] <- 'v2'
}
if (!inherits(error, 'error')){
class(fb_oauth)[4] <- 'v1'
}
return(fb_oauth)
}
clave1 <- fbOAuth("277743025645179", "6da12c05670a8425b4c58efe01db3634", extended_permissions=FALSE, legacy_permissions=FALSE, scope=NULL)
clave1 <- fbOAuth("277743025645179", "6da12c05670a8425b4c58efe01db3634", extended_permissions=FALSE, legacy_permissions=FALSE, scope=NULL)
clave1
me <- getUsers("me", token = clave1)
View(me)
me1 <- getUsers("me", token = clave)
quit()
shiny::runApp('tmp/App01')
quit()
if( !(file.exists("data/data_activity.zip") == TRUE) ){
dir.create('data')
download.file("http://d396qusza40orc.cloudfront.net/repdata/data/activity.zip", destfile="data/data_activity.zip")
unzip('data/data_activity.zip', exdir='data')
print("data cargada")
}else{
print(" existe data ")
}
data <- read.csv('data/activity.csv')
head(data)
nrow(data)
subdata = data[!is.na(data$steps), ]
head(subdata)
nrow(data)
num.steps.date <- aggregate(subdata$steps, list(subdata$date), sum)
colnames(num.steps.date) <- c("date", "steps")
head(num.steps.date)
View(data)
View(subdata)
View(num.steps.date)
library(ggplot2)
#hist
ggplot(data=num.steps.date, aes(x=steps)) +
geom_histogram(fill="#880011") +
ggtitle("Steps Taken per Day") +
labs(x="Number of Steps per Day", y="Number of times in a day")
class(num.steps.date$date)
num.steps.date$date
a <- num.steps.date$date
a
b <- character(a)
as.Date.character(a)
b <- as.Date.character(a)
b
num.steps.date$newdate <- as.character.Date(num.steps.date$date)
class(num.steps.date$newdate)
c <- data.frame(as.Date(num.steps.date$newdate, "%Y/%m/%d"),num.steps.date$steps)
View(c)
as.Date(num.steps.date$newdate,"%m/%d/%Y")
as.Date(num.steps.date$newdate,"%Y/%m/%d")
b
as.Date(b,"%Y/%m/%d")
d <- as.Date(b,"%Y/%m/%d")
class(d)
as.Date(num.steps.date$date,"%Y/%m/%d")
num.steps.date
View(num.steps.date)
num.steps.date <- aggregate(subdata$steps, list(subdata$date), sum)
colnames(num.steps.date) <- c("date", "steps")
head(num.steps.date)
View(num.steps.date)
temp <- aggregate(subdata$steps, list(subdata$date), sum)
View(temp)
temp$Group.1
temp.date <- as.Date.character(temp$Group.1)
temp.date
temp.date.character <- as.Date.character(temp$Group.1)
temp.date <- as.Date(temp.date.character, "%Y/%m/%d")
temp.date
class(temp.date)
num.steps.date <- data.frame(temp.date, temp$x)
View(num.steps.date)
colnames(num.steps.date) <- c("date", "steps")
head(num.steps.date)
ggplot(data=num.steps.date, aes(x=steps)) +
geom_histogram(fill="#880011") +
ggtitle("Steps Taken per Day") +
labs(x="Number of Steps per Day", y="Number of times in a day")
ggplot(data=num.steps.date, aes(date,steps)) +
geom_histogram(fill="#880011") +
ggtitle("Steps Taken per Day") +
labs(x="Number of Steps per Day", y="Number of times in a day")
ggplot(num.steps.date, aes(date, price)) +
geom_line()
ggplot(num.steps.date, aes(date, steps)) +
geom_line()
ggplot(data=num.steps.date, aes(date,steps)) +
geom_line(fill="#880011") +
ggtitle("Steps Taken per Day") +
labs(x="Number of Steps per Day", y="Number of times in a day")
num.steps.date <- aggregate(subdata$steps, list(subdata$date), sum)
View(num.steps.date)
colnames(num.steps.date) <- c("date", "steps")
head(num.steps.date)
head(num.steps.date)
ggplot(data=num.steps.date, aes(date,steps)) +
geom_line(fill="#880011") +
ggtitle("Steps Taken per Day") +
labs(x="Number of Steps per Day", y="Number of times in a day")
ggplot(data=num.steps.date, aes(date,steps)) +
geom_histogram(fill="#880011") +
ggtitle("Steps Taken per Day") +
labs(x="Number of Steps per Day", y="Number of times in a day")
data <- read.csv('data/activity.csv')
head(data)
nrow(data)
subdata = data[!is.na(data$steps), ]
head(subdata)
nrow(data)
temp <- aggregate(subdata$steps, list(subdata$date), sum)
temp.date.character <- as.Date.character(temp$Group.1)
temp.date <- as.Date(temp.date.character, "%Y/%m/%d")
num.steps.date <- data.frame(temp.date, temp$x)
colnames(num.steps.date) <- c("date", "steps")
head(num.steps.date)
ggplot(data=num.steps.date, aes(date,steps)) +
geom_line(fill="#880011") +
ggtitle("Steps Taken per Day") +
labs(x="Number of Steps per Day", y="Number of times in a day")
View(num.steps.date)
subdata$steps
mean(subdata$steps)
temp <- aggregate(subdata$steps, list(subdata$date), mean )
View(temp)
subdata
a <- subdata[subdata$date="2012-10-02"]
a <- subdata[subdata$date="2012-10-02",]
a <- subdata[subdata$date=="2012-10-02",]
a
mean(a)
mean(a$steps)
nrow(a$steps)
nrow(a)
install.packages("magick")
install.packages("magick", dependencies = TRUE)
library(magick)
x <- image_read("/home/pc/train/00087a6bd4dc_01.jpg")
x
image_info(x)
y <- image_border(x, "red", "20x10")
getwd()
y
image_scale(x, 400)
image_scale(x, "400")
z <- image_scale(x, "400")
image_background(z, "blue", flatten = FALSE)
z1 <- image_background(z, "blue", flatten = FALSE)
z1
z1 <- image_background(z, "blue", flatten = TRUE)
z1
image_flatten(z1, "Add")
image_flatten(z1, 'Add')
image_write(z1, path = tiff_file, format = 'tiff')
tiff_file <- tempfile()
image_write(z1, path = tiff_file, format = 'tiff')
r <- raster::brick(tiff_file)
r <- raster::brick(z1)
image_fill(z1, "blue", point = "+100+200", fuzz = 30000))
image_fill(z1, "blue", point = "+100+200", fuzz = 30000)
image_fill(z1, "black", point = "+100+200", fuzz = 30000)
image_fill(z1, "black", point = "+100+200", fuzz = 10000)
image_fill(z1, "white", point = "+100+200", fuzz = 10000)
image_fill(z1, "white", point = "+100+200", fuzz = 20000)
image_fill(z1, "white", point = "+100+200", fuzz = 30000)
image_fill(z1, "white", point = "+100+200", fuzz = 1000)
image_fill(z1, "blue", "+100+200")
image_fill(z1, "white", point = "+100+200", fuzz = 1000)
image_fill(z1, "blue", "+100+200")
image_fill(z1, "white", point = "+100+200", fuzz = 1000)
image_fill(z1, "blue", "+100+200")
image_fill(z1, "white", "+100+200000")
image_fill(z1, "white", "+900+800")
image_fill(z1, "white", "+900+800")
image_average(z1)
image_chop(z1,geometry = point)
image_chop(z1)
image_device(width = 600, height = 600, bg = "transparent",
pointsize = 12, res = 72, clip = TRUE)
image_noise(z1)
image_noise(z1)
image_device(width = 600, height = 600, bg = "transparent",
pointsize = 12, res = 72, clip = TRUE)
image_noise(z1)
image_noise(z1)
image_noise(z1)
image_noise(z1)
image_edge(z1)
z1
image_oilpaint(z1)
image_emboss(z1)
image_emboss(z1)
z2 <- image_emboss(z1)
z2 <- image_emboss(z2)
image_emboss(z2)
image_emboss(z1)
image_enhance(z1)
image_equalize(z1)
image_fill(image_flatten(z1), "red")
image_fill(image_flatten(z1), "red")
View(temp)
load.data.file <- function(arg) {
con <- file(arg,open="r")
line <- readLines(con, skipNul = TRUE)
close(con)
line
}
porcentaje.data.file <- function(arg, valor) {
tmp <- sample(arg, size = length(arg) * valor)
tmp
}
file1 <- load.data.file("final/en_US/en_US.blogs.txt")
file2 <- load.data.file("final/en_US/en_US.news.txt")
file3 <- load.data.file("final/en_US/en_US.twitter.txt")
file1.percent <- porcentaje.data.file(file1, 0.01)
file2.percent <- porcentaje.data.file(file2, 0.01)
file3.percent<- porcentaje.data.file(file3, 0.01)
library("tm")
#This SnowballC package contains a method to reduce a word to its root.
library("SnowballC")
#Wordcloud package is useful for creating a word cloud
library("wordcloud")
library("RColorBrewer")
files.percent <- VectorSource(c(file1.percent, file2.percent, file3.percent))
corpus <- Corpus(files.percent)
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, stripWhitespace)
summary(corpus)
corpus
tdm <- TermDocumentMatrix(corpus)
m <- as.matrix(tdm)
exit
quit()
install.packages("sparklyr")
library(sparklyr)
sc <- spark_connect(master = "local")
sdf_len(sc, 5, repartition = 1) %>%
spark_apply(function(e) I(e))
getwd()
if(!file.exists("2008.csv.bz2"))
{download.file("http://stat-computing.org/dataexpo/2009/2008.csv.bz2", "2008.csv.bz2")}
spark_read_csv(sc, "flights_spark_2008", "2008.csv.bz2", memory = FALSE)
flights_table <- tbl(sc,"flights_spark_2008") %>%
mutate(DepDelay = as.numeric(DepDelay),
ArrDelay = as.numeric(ArrDelay),
DepDelay > 15 , DepDelay < 240,
ArrDelay > -60 , ArrDelay < 360,
Gain = DepDelay - ArrDelay) %>%
filter(ArrDelay > 0) %>%
select(Origin, Dest, UniqueCarrier, Distance, DepDelay, ArrDelay, Gain)
library(dplyr)
library(ggplot2)
flights_table <- tbl(sc,"flights_spark_2008") %>%
mutate(DepDelay = as.numeric(DepDelay),
ArrDelay = as.numeric(ArrDelay),
DepDelay > 15 , DepDelay < 240,
ArrDelay > -60 , ArrDelay < 360,
Gain = DepDelay - ArrDelay) %>%
filter(ArrDelay > 0) %>%
select(Origin, Dest, UniqueCarrier, Distance, DepDelay, ArrDelay, Gain)
View(data)
sdf_register(flights_table, "flights_spark")
tbl_cache(sc, "flights_spark")
library(sparklyr)
library(dplyr)
library(ggplot2)
conf <- spark_config()
sc <- spark_connect(master = "local")
spark_read_csv(sc, "flights_spark_2008", "2008.csv.bz2", memory = FALSE)
flights_table <- tbl(sc,"flights_spark_2008") %>%
mutate(DepDelay = as.numeric(DepDelay),
ArrDelay = as.numeric(ArrDelay),
DepDelay > 15 , DepDelay < 240,
ArrDelay > -60 , ArrDelay < 360,
Gain = DepDelay - ArrDelay) %>%
filter(ArrDelay > 0) %>%
select(Origin, Dest, UniqueCarrier, Distance, DepDelay, ArrDelay, Gain)
flights_table
class(flights_table)
sdf_register(flights_table, "flights_spark")
tbl_cache(sc, "flights_spark")
c(1, FALSE)
c("a", 1)
c(list(1), "a")
c(TRUE, 1L)
c(1, FALSE)
c("a", 1)
c(list(1), "a")
c(TRUE, 1L)
a1 <- c(1, FALSE)
a2 <- c("a", 1)
a3 <- c(list(1), "a")
a4 <- c(TRUE, 1L)
a1
a2
a3
a4
a3[1]
a3[2]
df <- data.frame(c(1:5),a3)
df
b <- matrix(c(1:5), a3)
b <- matrix(c(1:5))
b <- matrix(a3)
b
b <- matrix(c(1:2), a3)
b <- matrix(c(1:2))
b
x <- data.frame(c(1:5),b)
x <- data.frame(c(1:2),b)
x
y <- list(b)
y
is.vector(b)
is.character(b)
a4
dim(a1)
dim(a2)
dim(a3)
dim(c(1:10))
exit
quit
quit()
library("base64enc")
library("twitteR")
library("ROAuth")
library("devtools")
library("memoise")
library("whisker")
library("rstudioapi")
library("git2r")
library("withr")
library("rjson")
library("bit64")
library ("httr")
library ("httpuv")
consumer_key <- "Glr9jtLvxgBN8KSEHwENgH2xe"
consumer_secret <- "BnfC6LGUsLl6P7lMTUbqs5WmpzEAlhhjJn5PQJhYntFflcrR9c"
access_token <- "3017944222-lW7ZnvLdW79fWxvUQM8LYcw8418bkJOFzD7kNuI"
access_secret <- "4I0e9lqk1uOsNzWlq8ig0e29gub7S5MfvhXX5Gbj4g0qF"
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
r1 <- twitteR::searchTwitter('#AraSiVotarem', n=500, resultType="popular")
r2 = twitteR::twListToDF(r1)
View(r2)
r2["statusSource",]
r2["statusSource"]
quit()
palabras <- read.delim("~/AAA_AnalisisIngles/palabras.txt", header=FALSE)
View(palabras)
palabras$V4=null;
palabras$V4 <- null
palabras$V4 <- null;
palabras[4] <- NULL
palabras1 <- palabras
View(palabras1)
palabras1[with(palabras1, order(V2)) ]
palabras2 <- palabras1[with(palabras1, order(V2)) ]
palabras2 <- palabras1[with(palabras1, order(V2)), ]
View(palabras2)
palabras2$V2==NA
palabras2$V2 != NA
palabras2$V2 != 'Adjetivo'
palabras2[, is.na(V2)]
palabras2[, is.na(V2),]
palabras2[, is.na(palabras2$V2),]
palabras2[, is.na(palabras2$V2)]
palabras2[, !is.na(palabras2$V2)]
palabras2[palabras2$V2 == NA, ]
palabras3 <- palabras2[palabras2$V2 == NA, ]
View(palabras3)
palabras3 <- palabras2[palabras2$V2 == 'Adjetivo', ]
View(palabras3)
palabras3 <- palabras2[palabras2$V2 == '', ]
setwd("~/Dic2018/DataSciences-week2-r-programming-Programming-Assignment-2")
makeCacheMatrix <- function(x = matrix()) {
m<-NULL
set<-function(y){
x<<-y
m<<-NULL
}
get<-function() x
setmatrix<-function(solve) m<<- solve
getmatrix<-function() m
list(set=set, get=get, setmatrix=setmatrix, getmatrix=getmatrix)
}
## Write a short comment describing this function
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
m<-x$getmatrix()
if(!is.null(m)){
message("getting cached data")
return(m)
}
matrix<-x$get()
m<-solve(matrix, ...)
x$setmatrix(m)
m
}
a <- c(1:1000)
b <- mean(a)
c <- cacheSolve(b)
a <- makeCacheMatrix(1:1000)
a$get()
a$getmatrix()
cacheSolve(a)
a
a
a$get()
a <- makeCacheMatrix(1:1000000)
cacheSolve(a)
a <- makeCacheMatrix(1:1000)
cacheSolve(a)
m <- NULL
set <- function(y){ x <<- y, m <<- NULL}
set <- function(y){ x <<- y m <<- NULL}
m<-NULL
set<-function(y){
x<<-y
m<<-NULL
}
m
set
set(234)
x
get()
get(x)
get<-function() x
get()
setmatrix<-function(solve) m<<- solve
getmatrix<-function() m
solve()
getmatrix()
list(set=set, get=get, setmatrix=setmatrix, getmatrix=getmatrix)
makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
a <- makeVector(1:100)
a$get()
a$set(1:10)
a$get()
a$getmean()
a$setmean(1:10)
a$getmean()
a$setmean(3.45)
a$getmean()
m <<- mean()
m <<- mean(1:10)
m
a$getmean()
cachemean <- function(x, ...) {
m <- x$getmean()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- mean(data, ...)
x$setmean(m)
m
}
cachemean(a)
a
a$get()
a$getmean()
